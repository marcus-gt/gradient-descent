{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OUTLINE / INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I denne notebooken gir jeg svar på oppgavene. Unntaket er den første oppgaven (Task 0), som ligger i en separat PDF. Oppgavene besvares i all hovedsak under oversriften \"Mini-batch (Stochastic) Gradient Descent\", så hopp gjerne rett til den. Grunnen til at jeg har med to løsninger er at jeg først løste oppgaven ved hjelp av \"vanlig\" Stochstic Gradient Descent – der man kun velger én av observasjonene. Dette har jeg bedre kjennskap til fra før, så jeg startet her – deretter utvidet jeg til en mini-batch løsning slik det etterspørres i oppgaven. \n",
    "\n",
    "Notebooken er strukturert som følger:\n",
    "1. I Del 1 en gir jeg et raskt overblikk over den generelle algoritmen for Gradient Descent som jeg har fulgt i løsningen\n",
    "2. I Del 2 genereres det dummy-data som kan brukes til å vurdere/evaluere modellen(e)\n",
    "3. I Del 3 bygges et program som løser oppgaven ved hjelp av \"vanlig\" Stochastic gradient descent\n",
    "4. I Del 4 bygges et program som løser oppggaven ved hjelp av mini-batch stochastic gradient descent. Denne gir svar på Task 3, 5 og 6.\n",
    "5. Del 5 gir en funksjon som produserer jacobian, slik det etterspørres i Task 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Genral approach/algorithm that I've followed in the solution\n",
    "1. Take the gradient of the loss-function \n",
    "2. Pick random starting values for the parameters that are to be estimated\n",
    "3. Caculate the gradient with the current values\n",
    "4. Calculate the value for the next step: old_value - learning_rate*gradient(current_values)\n",
    "5. Back to step 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Generating some dummy-data\n",
    "For testing/verifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11d98afd0>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# True values of the parameters - what I'm trying to estimate later\n",
    "c_true = 1.5\n",
    "mu_true = 0.5\n",
    "\n",
    "# Genrating some input and outout data, last term adds \n",
    "X = np.random.rand(100,1)\n",
    "y = c_true*(np.exp(-((X-mu_true)**2)/2)) + np.random.rand(100,1)/10\n",
    "plt.plot(X, y, 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Stochastic Gradient Descent\n",
    "Picking a single value from the data for each step in the algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################\n",
    "### 1) HELPER FUNCTIONS\n",
    "###############################################################################################\n",
    "\n",
    "# 1.1) Function giving av value/vektor of the estimated y's given the current parameters SECTION 3 IN THE TEST\n",
    "def f(c,mu,x_vector):\n",
    "    return c*(np.exp(-((x_vector-mu)**2)/2))\n",
    "\n",
    "\n",
    "# 1.2 Gradient functions (SECTION 5 IN THE TEST)\n",
    "# 1.2.1) Function returning the gradient of the loss-function with respect to the parameter mu\n",
    "def gradient_mu(c,mu,x_vector,y_vector):\n",
    "    N = len(x_vector)\n",
    "    return 2*(f(c,mu,x_vector) - y_vector) * c *(np.exp(-((x_vector-mu)**2)/2))*(x_vector-mu)/2\n",
    "\n",
    "# 1.2.2) Function returning the gradient of the loss-function with respect to the parameter c\n",
    "def gradient_c(c,mu,x_vector,y_vector):\n",
    "    N = len(x_vector)\n",
    "    return 2*(f(c,mu,x_vector) - y_vector) * np.exp(-((x_vector-mu)**2)/2) #/ N\n",
    "\n",
    "###############################################################################################\n",
    "### 2) STOCHASTIUC GRADIENT DESCENT FUNCTIION\n",
    "###############################################################################################\n",
    "\n",
    "def stochastic_gradient_descent(x_vector, y_vector, learning_rate = 0.01, max_num_steps = 1000):    \n",
    "    # Pick random starting values for the parameters c and mu\n",
    "    c = np.random.uniform(0,1,1)\n",
    "    mu = np.random.uniform(0,1,1)\n",
    "    \n",
    "    steps = 0\n",
    "    while steps < max_num_steps:\n",
    "        \n",
    "        # Stochastic element - picking single values for x,y for stochastic gradient descent\n",
    "        permutation = np.random.permutation(len(x_vector))\n",
    "        x = x_vector[permutation][0]\n",
    "        y = y_vector[permutation][0]\n",
    "        \n",
    "        # Calculating new parameters for next step\n",
    "        c = c - learning_rate*gradient_c(c,mu,x,y)\n",
    "        mu = mu - learning_rate*gradient_mu(c,mu,x,y)\n",
    "        \n",
    "        # Updating steps (adding 1)\n",
    "        steps += 1\n",
    "    \n",
    "    return (c,mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real c-value: 1.5 \n",
      "Real c-value: 0.5 \n",
      "Estimated c-value: 1.562092667994107 \n",
      "Estimated c-value: 0.5018793967736604\n"
     ]
    }
   ],
   "source": [
    "SGD = stochastic_gradient_descent(X,y)\n",
    "print(f\"Real c-value: {c_true} \\nReal c-value: {mu_true} \\nEstimated c-value: {float(SGD[0])} \\nEstimated c-value: {float(SGD[1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Mini-batch (Stochastic) Gradient Descent\n",
    "Selecting a random batch of the data for each step-calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################\n",
    "### 1) HELPER FUNCTIONS\n",
    "###############################################################################################\n",
    "\n",
    "# 1.1) Function giving av value/vector of the estimated y's given the current parameters (same as above)\n",
    "def f(c,mu,x_vector):\n",
    "    return c*(np.exp(-((x_vector-mu)**2)/2))\n",
    "\n",
    "# 1.2 Gradient functions. These differs from the ones above in that they calculate the average gradients for all the observations in the vector (given by N)\n",
    "# 1.2.1) Function returning the gradient of the loss-function with respect to the parameter mu\n",
    "def gradient_c(c, mu, x_vector, y_vector):     \n",
    "    N = len(y_vector)\n",
    "    gradient = 0\n",
    "    for x, y in zip(x_vector, y_vector):\n",
    "        gradient += 2*(f(c, mu, x) - y) * np.exp(-((x-mu)**2)/2)\n",
    "    return gradient/N\n",
    "\n",
    "# 1.2.1) Function returning the gradient of the loss-function with respect to the parameter mu\n",
    "def gradient_mu(c, mu, x_vector, y_vector):         \n",
    "    N = len(y_vector)\n",
    "    gradient = 0\n",
    "    for x,y in zip(x_vector, y_vector):\n",
    "        gradient += 2*(f(c, mu, x) - y) * c *(np.exp(-((x-mu)**2)/2))*(x-mu)/2\n",
    "    return gradient/N\n",
    "\n",
    "###############################################################################################\n",
    "### 2) MINI-BATCH (STOCHASTIC) GRADIENT DESCENT FUNCTIION\n",
    "###############################################################################################\n",
    "\n",
    "def mini_batch_gradient_descent(x_vector, y_vector, learning_rate = 0.01, runs = 1000, batch_size=100):  \n",
    "   # Pick random starting values for the parameters c and mu\n",
    "    c = np.random.uniform(0,1,1)\n",
    "    mu = np.random.uniform(0,1,1)\n",
    "    \n",
    "    # Stochastic element - picking batch of values from the data\n",
    "    permutation = np.random.permutation(len(x_vector))\n",
    "    x = x_vector[permutation][0:batch_size]\n",
    "    y = y_vector[permutation][0:batch_size]    \n",
    "    \n",
    "     # Calculating new parameters\n",
    "    for i in range(runs):\n",
    "        c -= learning_rate*gradient_c(c,mu,x,y)\n",
    "        mu -= learning_rate*gradient_mu(c,mu,x,y)\n",
    "    \n",
    "    return (c,mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real c-value: 1.5 \n",
      "Real c-value: 0.5 \n",
      "Estimated c-value: 1.5550759341543965 \n",
      "Estimated c-value: 0.47176641105699385\n"
     ]
    }
   ],
   "source": [
    "MBGD = mini_batch_gradient_descent(X,y)\n",
    "print(f\"Real c-value: {c_true} \\nReal c-value: {mu_true} \\nEstimated c-value: {float(MBGD[0])} \\nEstimated c-value: {float(MBGD[1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Jacobian\n",
    "Matrix with values for the first dirivatives -  Section 4 answer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since I used a somewhat different approach I never calculated the jacobian explicitly. Here I present a function returning the jacobian as asked in section 5\n",
    "def jacobian_matrix(x_vector, c, mu):\n",
    "    return np.hstack([\n",
    "        c*(np.exp(-((x_vector-mu)**2)/2))*(x_vector-mu)/2    # derivitve of f with respect to c (param 1)\n",
    "        , np.exp(-((x_vector-mu)**2)/2)                      # derivitve of f with respect to mu (param 2)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.12903438,  0.94319011],\n",
       "       [ 0.01626879,  0.99917187],\n",
       "       [-0.04766666,  0.9928225 ],\n",
       "       [ 0.23234203,  0.72629149],\n",
       "       [ 0.21501379,  0.79621174],\n",
       "       [-0.06101842,  0.98815495],\n",
       "       [ 0.06623605,  0.98599674],\n",
       "       [ 0.08182157,  0.97838117],\n",
       "       [-0.0706072 ,  0.98403997],\n",
       "       [ 0.06830338,  0.98508835],\n",
       "       [ 0.13417928,  0.93806352],\n",
       "       [-0.00665479,  0.99986158],\n",
       "       [ 0.16586553,  0.89911012],\n",
       "       [ 0.00965177,  0.99970876],\n",
       "       [ 0.2115516 ,  0.80654787],\n",
       "       [-0.0083728 ,  0.99978085],\n",
       "       [ 0.17665843,  0.88223156],\n",
       "       [ 0.19804749,  0.84082541],\n",
       "       [ 0.12835603,  0.94384449],\n",
       "       [ 0.16899423,  0.89444214],\n",
       "       [-0.03386024,  0.99639769],\n",
       "       [ 0.14861089,  0.92202477],\n",
       "       [ 0.1277829 ,  0.94439355],\n",
       "       [ 0.05119415,  0.9917069 ],\n",
       "       [ 0.19612446,  0.84509386],\n",
       "       [ 0.04712824,  0.99298546],\n",
       "       [ 0.03215582,  0.99675296],\n",
       "       [-0.02904428,  0.99735334],\n",
       "       [ 0.23229958,  0.72652675],\n",
       "       [ 0.17848894,  0.87913888],\n",
       "       [-0.02762704,  0.99760624],\n",
       "       [ 0.0078803 ,  0.99980588],\n",
       "       [ 0.10187716,  0.96582755],\n",
       "       [ 0.21634483,  0.7920195 ],\n",
       "       [ 0.02250962,  0.99841284],\n",
       "       [ 0.16099459,  0.90604393],\n",
       "       [ 0.17386942,  0.88680884],\n",
       "       [-0.06735192,  0.98551021],\n",
       "       [ 0.20368792,  0.82750694],\n",
       "       [ 0.23009389,  0.73807456],\n",
       "       [ 0.08265205,  0.97792462],\n",
       "       [ 0.19569112,  0.84603819],\n",
       "       [ 0.04989311,  0.99212808],\n",
       "       [ 0.08348405,  0.97746193],\n",
       "       [-0.05950192,  0.98874652],\n",
       "       [ 0.15346824,  0.91602158],\n",
       "       [ 0.05171492,  0.99153512],\n",
       "       [ 0.00749331,  0.99982449],\n",
       "       [ 0.05952591,  0.98873729],\n",
       "       [ 0.21743892,  0.78847292],\n",
       "       [ 0.20392951,  0.82690748],\n",
       "       [ 0.18571485,  0.86618666],\n",
       "       [ 0.01941528,  0.99881993],\n",
       "       [ 0.22871679,  0.74470678],\n",
       "       [ 0.12837653,  0.94382479],\n",
       "       [ 0.0120171 ,  0.99954841],\n",
       "       [ 0.20372699,  0.82741017],\n",
       "       [ 0.12377655,  0.9481352 ],\n",
       "       [ 0.0196915 ,  0.99878605],\n",
       "       [ 0.03755676,  0.99556265],\n",
       "       [ 0.05298688,  0.99110785],\n",
       "       [-0.01009895,  0.99968113],\n",
       "       [ 0.00755391,  0.99982163],\n",
       "       [ 0.12122503,  0.9504322 ],\n",
       "       [ 0.06903023,  0.98476171],\n",
       "       [ 0.16647975,  0.89820733],\n",
       "       [ 0.22250419,  0.77067955],\n",
       "       [ 0.154001  ,  0.915343  ],\n",
       "       [-0.05633901,  0.9899292 ],\n",
       "       [ 0.00467953,  0.99993156],\n",
       "       [-0.03238568,  0.99670614],\n",
       "       [ 0.17890023,  0.87843401],\n",
       "       [-0.06751843,  0.98543685],\n",
       "       [ 0.00355912,  0.99996041],\n",
       "       [-0.00275963,  0.9999762 ],\n",
       "       [ 0.08281902,  0.97783219],\n",
       "       [ 0.0802036 ,  0.97925556],\n",
       "       [ 0.19036159,  0.85716185],\n",
       "       [ 0.0638703 ,  0.98699902],\n",
       "       [ 0.16545162,  0.89971481],\n",
       "       [ 0.2248994 ,  0.76131517],\n",
       "       [-0.03741998,  0.99559513],\n",
       "       [ 0.20546225,  0.82304381],\n",
       "       [ 0.21546731,  0.79479789],\n",
       "       [ 0.1338501 ,  0.93840034],\n",
       "       [ 0.05676366,  0.98977441],\n",
       "       [ 0.18525293,  0.86705244],\n",
       "       [-0.00769419,  0.99981495],\n",
       "       [ 0.21561715,  0.79432751],\n",
       "       [ 0.14770451,  0.92310933],\n",
       "       [ 0.22601388,  0.75670214],\n",
       "       [ 0.12844364,  0.94376026],\n",
       "       [ 0.19464195,  0.84829866],\n",
       "       [-0.06951996,  0.98453949],\n",
       "       [ 0.18482709,  0.86784583],\n",
       "       [ 0.22968764,  0.74007253],\n",
       "       [-0.02134162,  0.99857362],\n",
       "       [ 0.0695997 ,  0.98450315],\n",
       "       [ 0.21174402,  0.80599337],\n",
       "       [ 0.01630623,  0.99916805]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## With example estimates for the parameters:\n",
    "J_c = 0.8\n",
    "J_mu = 0.2\n",
    "\n",
    "jacobian_matrix(X, J_c, J_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "225px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
